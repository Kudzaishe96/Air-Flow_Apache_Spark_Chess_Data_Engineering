FROM python:3.10.13-slim

# Install Java and dependencies
RUN apt-get update && apt-get install -y \
    openjdk-17-jdk \
    curl \
    bash \
    && apt-get clean

# Set environment variables
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH="$JAVA_HOME/bin:$PATH"

# Install Spark
ENV SPARK_VERSION=4.0.0
ENV HADOOP_VERSION=3

RUN curl -L "https://downloads.apache.org/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz" \
    | tar -xz -C /opt/ \
    && mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /opt/spark

ENV SPARK_HOME=/opt/spark
ENV PATH="$SPARK_HOME/bin:$PATH"

# Set PySpark environment variables
ENV PYSPARK_PYTHON=python3.10
ENV PYSPARK_DRIVER_PYTHON=python3.10

WORKDIR /opt/spark
CMD ["/bin/bash"]

RUN pip install pycountry